# Kairós, Caerus, Opportunity, and the Wheel of Fortune
- "The opportune moment, coming and being made use of" (Thucydides)

## Seizing Opportunities
καιρός - The ancient greek god of opportunity. Zeus youngest is also known as Caerus (i.e. latinised form of καιρός) or Occasio. 

### Facts about Kairós
* Kairos is "a symbol of Opportunity, the brief moment in which things are possible" by Aesop
* "action at the right moment; Kairos comes and can be lost, unless it is used" by Thucydides
* "a unique situation without recurrence" by Posidippus
* "In every work of art, the beautiful is accomplished by many measurements coming into Kairos by a certain symmetry and harmony; the ugly emerges, however, when a single accidental element is lacking or added" by Polykleitos cited by Plutarch
* the German saying "[die Gelegenheit beim Schopfe packen](https://de.wiktionary.org/wiki/die_Gelegenheit_beim_Schopfe_packen)" (lit. to grab opportuinity by the forelock / tuft of hair), meaning to "seize the opportunity" or "snap at the chance"
* "The juvenile god has just descended from the heights, is present in this very moment, and can immediately withdraw again by using once more his large spinal wings or by running away, sped up by his foot wings. So, it is exactly the unpredictability of Kairos that is described." (D. Boschung about the Lysippian Kairos)
* "a brief, decisive moment which marks a turning-point in the life of human beings or in the development of the universe" by Panofsky
* "i øjeblikket" by Kierkegaard, which describes a brief moment of endless possibilities
* Sophists see Kairos as a rhetoric ability to adapt to and take advantage of changing and contingent circumstances

### Read More
* [Wikipedia_EN::Kairos](https://en.wikipedia.org/wiki/Kairos)
* [Wikipedia_EN::Caerus](https://en.wikipedia.org/wiki/Caerus)
* [Kairos as a Figuration of Time, D. Boschung, 2013](https://core.ac.uk/download/pdf/129682979.pdf)
* [Review of D. Shanske's "Thucydides and the Philosophical Origins of History", J. Reynolds, 2007](https://ndpr.nd.edu/reviews/thucydides-and-the-philosophical-origins-of-history/)
* [Designing Information Systems that can Sense & Seize Kairos, P. Daniel, 2016](https://projekter.aau.dk/projekter/files/239571461/DanielP_Master_Thesis.pdf)
* [Fables, Aesop](http://www.mythfolklore.net/aesopica/oxford/536.htm)

## What For
This is my personal ideation dump. Here, I plan to place my project ideas - from stupid to simple to even greater in procrastinative nature. But always with a certain quality of "making" and "achieving". 

* Streamlit-based app for Paint by numbers for my nieces. 
    * Process: 
        * upload a random picture
        * transform image from source to areas: identify uniform/similar patterns, highlight edges, make everything white
        * export image to pdf (maybe scale up by jpg2svg??)
    * Challenge:
        * how to transform given input into dis-/similar areas
        * how to automatically achieve age-corresponding difficulty
    * Inspiration:
        * Awesome node repo by drake7707: [demo](https://drake7707.github.io/paintbynumbersgenerator/index.html), [code dump](https://github.com/drake7707/paintbynumbersgenerator)
        * Python-based repo by spluxx [code dump](https://github.com/spluxx/paint_by_numbers) or e-shrdlu [code dump](https://github.com/e-shrdlu/paint-by-numbers-generator) or LukaZdr [code dump](https://github.com/LukaZdr/paint_by_numbers_image_generator) or GulnazSerikbay [code dump](https://github.com/GulnazSerikbay/PBN)
* Fork [CMeyer29's X-Mas containerized Scratch game](https://github.com/cmeyer29/scratch-on-k3s) on own 
    * Challenge: 
        * Get reasonably priced RPi 4 (8GB) 
        * Get enough play money for proper miniITX/ATX sized system, e.g. Odroid H3 (Celeron N5105)
            * [heise on Hardkernel Odroid-H3](https://www.heise.de/select/ct/vorschau/2235712100679237451)
            * [Pollin::Odroid](https://www.pollin.de/p/odroid-h3-einplatinencomputer-811600)
            * [Notebookcheck](https://www.notebookcheck.com/Odroid-H3-und-H3-Neues-Mainboards-mit-Jasper-Lake-Prozessoren-und-bis-zu-64-Gigabyte-RAM.661710.0.html)
            * [Hardkernel Odroid H3+](https://www.hardkernel.com/shop/odroid-h3-plus/)
            * [Hardkernel Odroid H3](https://www.hardkernel.com/shop/odroid-h3/)
* Explore:
    * Gradio:[Official Repo](https://github.com/gradio-app/gradio), [Website](http://www.gradio.app/), [Gallery](https://www.gradio.app/demos/), [Docu/101](https://www.gradio.app/quickstart/)
    * Dash
    * Flet: [Official Repo](https://github.com/flet-dev/flet), [Website](https://flet.dev/), [Gallery](https://github.com/flet-dev/examples/tree/main/python), [Docu/101](https://flet.dev/docs/guides/python/getting-started/)
    * DistilBERT
      * Author Blog Post: [Smaller, faster, cheaper, lighter: Introducing DistilBERT, a distilled version of BERT](https://medium.com/huggingface/distilbert-8cf3380435b5)   
      * Research Paper: [DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter](https://arxiv.org/abs/1910.01108), [Papers with Code](https://paperswithcode.com/method/distillbert)
      * Huggingface::Transformers::[DistilBERT](https://huggingface.co/docs/transformers/model_doc/distilbert) (incl. various use cases)
      * PopSci Articles: [AIM: Python Guide to Huggingface DistilBERT - Smaller, Faster, Cheaper Distilled BERT](https://analyticsindiamag.com/python-guide-to-huggingface-distilbert-smaller-faster-cheaper-distilled-bert/), [AV: Intro to DistilBERT in Student Model](https://www.analyticsvidhya.com/blog/2022/11/introduction-to-distilbert-in-student-model/), [TDS::Distillation of BERT-Like Models: The Theory](https://towardsdatascience.com/distillation-of-bert-like-models-the-theory-32e19a02641f)
      * Wolfram Neural Net Repository::[DistilBERT Trained on BookCorpus and English Wikipedia Data - Represent text as a sequence of vectors](https://resources.wolframcloud.com/NeuralNetRepository/resources/DistilBERT-Trained-on-BookCorpus-and-English-Wikipedia-Data/)
      * Exemplary Notebook by A. Fogarty: [here](http://seekinginference.com/applied_nlp/distilbert.html); Notebook by P. Schmid: [here](https://github.com/philschmid/knowledge-distillation-transformers-pytorch-sagemaker/blob/master/knowledge-distillation.ipynb)
      * Knowledge Distillation: [Wikipedia](https://en.wikipedia.org/wiki/Knowledge_distillation), [Google Research::Distilling the Knowledge in a NN](https://research.google/pubs/pub44873/), [Distilling Knowledge to Specialist Networks for Clustered Classification](Distilling Knowledge to Specialist Networks for Clustered Classification), [Keras::Knowledge Distillation](https://keras.io/examples/vision/knowledge_distillation/), [Google Colab Knowledge Distillation](https://colab.research.google.com/drive/1Vo5rFF5JyHdJGFW88io4t5QS6q1klYPD?usp=sharing), IntelLabs::[Distiller](https://intellabs.github.io/distiller/), IntellLabs::[TransformerModelDistillation](https://intellabs.github.io/nlp-architect/transformers_distillation.html), UKPLab::[SentenceTransformers::Distillation](https://github.com/UKPLab/sentence-transformers/tree/master/examples/training/distillation), [FastFormers: Highly Efficient Transformer Models for Natural Language Understanding](https://arxiv.org/abs/2010.13382), [Distlling distilled transformers](https://lewtun.github.io/blog/weeknotes/nlp/huggingface/transformers/2021/01/17/wknotes-distillation-and-generation.html#fn-1)

* Upskill: 
    * npm/node


    
